install.packages(c('purrr','lubridate'))

library(tidyverse)
library(fixest)
library(ggstance)
library(vtable)
library(multcomp)
library(purrr)
library(lubridate)

#Reading in Google Trends Data
trends_files <- list.files(path = '.' , pattern='trends_', full.names=TRUE)

trends_files <- map_df(trends_files, read_csv) 

trends_files

#Aggregating the Google Trends Data: 
"Getting date data"

monthorweek <-str_sub(trends_files$monthorweek, 1,10) 
ymd(monthorweek) 
floor_date(monthorweek, unit= 'month')

"Aggregating"
trends_files %>% 
  group_by(schname, keyword) %>%
  mutate(index_id = (index-mean(index))/sd(index))

"Reading in Scorecard Data"
score <- read_csv('Most+Recent+Cohorts+(Scorecard+Elements).csv')
id_name_link <- read_csv('id_name_link.csv')

"Dropping variables from Scorecard data to make it smaller" 


'Remove university that share the same schname' 
id_name_link <- id_name_link %>%
                  group_by(schname) %>% 
                  mutate(n= n()) %>% 
                  filter ( n == 1)

'Make column name to lower case to match with id_name_link file'
names(score) <- tolower(names(score))
head(score,10)

'Merging the scorecard data'
join_files <- inner_join(id_name_link, trends_files, by='schname')
final_join <- inner_join(join_files, score, by='unitid')

'Save into one file' 
write_csv(final_join, "clean_data.csv")
